# parameters for the enviroment and model
[env]
m = 5                              # this is the number of rows of the grid
n = 5                              # this is the number of columns of the grid
model = "vit"                     # the available models are in src/registry/model_registry.py
env_type = "NoThreeCollinearEnvWithPriority"  # the available envs are in src/registry/env_registry.py
priority_function = "default"     # priority function: "default", "boundary", "distance", "collinear_count"

# which RL method to use
[algo]
method = 'mcts'                    # 'dqn', 'mcts', 'priority', 'mcts_priority'

# parameters for training
[train]
episodes = 100                     # the number of training epsisodes (or games for MCTS)
batch_size = 64                    # for DQN
gamma = 1.0                        # Gamma is the discount factor for reward. We set it to 1 for no discount.
epsilon = 0.1                      # epsilon is the probability for exploring (DQN)
lr = 0.0001                        # This is the learning rate (DQN)
target_update_freq = 10            # for DQN
memory_size = 10000                # for DQN
save_best_points = true            # save and print best point set at the end

# MCTS specific parameters
mcts_searches = 1000               # number of MCTS search iterations per move
mcts_c_param = 1.4                 # UCB exploration parameter
mcts_use_priority = true           # whether to use priority for action selection
mcts_top_n = 1                     # number of top priority levels to consider
mcts_progress = true               # show progress during training

# PatternBoost specific parameters
[patternboost]
learning_rate = 3e-4               # learning rate for transformer
weight_decay = 0.1                 # weight decay for transformer
betas = [0.9, 0.95]               # beta parameters for AdamW
initial_dataset_size = 1000        # number of initial configurations
top_percentage = 0.25              # percentage of top configs for training
generation_size = 100              # number of new configs to generate
max_iterations = 5                 # maximum number of iterations
batch_size = 32                    # batch size for training
epochs_per_iteration = 5           # epochs per iteration


# all the path are relative to the project root
[path]
project_root = './'
log_dir = './logs/'
model_dir = './saved_models/'